name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  PYTHON_VERSION: "3.11"
  
jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_ai_todo
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          pip install -r requirements.txt
          pip install pytest-cov aiosqlite bandit safety ruff black
          
      - name: Install Redis CLI
        run: |
          sudo apt-get update
          sudo apt-get install -y redis-tools

      - name: Set up environment variables
        run: |
          echo "TESTING=true" >> $GITHUB_ENV
          echo "TEST_DATABASE_URL=postgresql+asyncpg://test:test@localhost:5432/test_ai_todo" >> $GITHUB_ENV
          echo "REDIS_URL=redis://localhost:6379" >> $GITHUB_ENV
          echo "GEMINI_API_KEY=" >> $GITHUB_ENV
          echo "AI_ENABLED=false" >> $GITHUB_ENV

      - name: Wait for services
        run: |
          echo "Waiting for PostgreSQL..."
          timeout 60 bash -c 'until pg_isready -h localhost -p 5432 -U test; do echo "Waiting for postgres..."; sleep 1; done'
          echo "PostgreSQL is ready!"
          
          echo "Waiting for Redis..."
          timeout 60 bash -c 'until redis-cli -h localhost -p 6379 ping | grep -q PONG; do echo "Waiting for redis..."; sleep 1; done'
          echo "Redis is ready!"

      - name: Run unit tests
        run: |
          python run_tests.py --unit --verbose

      - name: Run integration tests
        run: |
          python run_tests.py --integration --verbose

      - name: Run API tests
        run: |
          python run_tests.py --api --verbose

      - name: Run E2E tests
        run: |
          python run_tests.py --e2e --verbose

      - name: Generate coverage report
        run: |
          python -m pytest tests/ --cov=app --cov-report=xml --cov-report=html --cov-fail-under=80

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

  code-quality:
    name: Code Quality Checks (Modern Toolchain)
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install modern code quality tools
        run: |
          python -m pip install --upgrade pip
          pip install ruff black pylint

      - name: Run comprehensive quality checks
        run: |
          python quality_check.py

      # Alternative: Individual steps for detailed error reporting
      # - name: Check imports and linting with Ruff (Fast)
      #   run: |
      #     ruff check app/ tests/ --output-format=github
      # 
      # - name: Check code formatting with Black
      #   run: |
      #     black --check --diff app/ tests/
      # 
      # - name: Deep code analysis with Pylint
      #   run: |
      #     pylint app/ --score=y --fail-under=9.5

  security:
    name: Security Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies and security tools
        run: |
          python -m pip install --upgrade pip setuptools
          pip install -r requirements.txt
          pip install bandit safety semgrep

      - name: Run Bandit security linter
        run: |
          bandit -r app/ -f json -o bandit-report.json || true
          bandit -r app/ -ll -i -x */tests/*

      - name: Check dependencies for known vulnerabilities
        run: |
          safety check --json --output safety-report.json || true
          safety check

      - name: Run Semgrep security analysis
        run: |
          semgrep --config=auto app/ --json --output=semgrep-report.json || true
          semgrep --config=auto app/
        continue-on-error: true

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json
            semgrep-report.json

  dependency-check:
    name: Dependency Analysis
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies and pip-audit
        run: |
          python -m pip install --upgrade pip setuptools
          pip install -r requirements.txt
          pip install pip-audit

      - name: Audit dependencies
        run: |
          pip-audit --format=json --output=pip-audit-report.json || true
          pip-audit

      - name: Upload dependency report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: dependency-report
          path: pip-audit-report.json

  docker:
    name: Docker Build Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        run: |
          docker build -t todolist-backend:test .
          
      - name: Test Docker image
        run: |
          # Test that the image was built successfully
          docker images | grep todolist-backend:test

  performance:
    name: Performance Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_ai_todo
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest-benchmark locust

      - name: Set up environment variables
        run: |
          echo "TEST_DATABASE_URL=postgresql+asyncpg://test:test@localhost:5432/test_ai_todo" >> $GITHUB_ENV
          echo "TESTING=true" >> $GITHUB_ENV

      - name: Check for benchmark tests
        id: check-benchmarks
        run: |
          if grep -r "benchmark\|@pytest.mark.benchmark" tests/ --include="*.py" > /dev/null 2>&1; then
            echo "benchmark_tests=true" >> $GITHUB_OUTPUT
          else
            echo "benchmark_tests=false" >> $GITHUB_OUTPUT
            echo "No benchmark tests found, creating a simple performance check"
          fi

      - name: Run benchmark tests
        if: steps.check-benchmarks.outputs.benchmark_tests == 'true'
        run: |
          python -m pytest tests/ -k "benchmark" --benchmark-only --benchmark-json=benchmark.json

      - name: Run basic performance check
        if: steps.check-benchmarks.outputs.benchmark_tests == 'false'
        run: |
          echo "Running basic performance validation..."
          # Test database connection performance
          python -c "
          import asyncio
          import time
          from sqlalchemy.ext.asyncio import create_async_engine
          
          async def test_db_performance():
              engine = create_async_engine('${{ env.TEST_DATABASE_URL }}')
              start_time = time.time()
              async with engine.connect() as conn:
                  await conn.execute('SELECT 1')
              end_time = time.time()
              connection_time = (end_time - start_time) * 1000
              print(f'Database connection time: {connection_time:.2f}ms')
              if connection_time > 1000:  # 1 second threshold
                  print('WARNING: Database connection is slow')
              else:
                  print('Database connection performance is acceptable')
              await engine.dispose()
          
          asyncio.run(test_db_performance())
          "

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: steps.check-benchmarks.outputs.benchmark_tests == 'true'
        with:
          name: benchmark-results
          path: benchmark.json

  build-production-image:
    name: Build Production Image
    runs-on: ubuntu-latest
    needs: [test, code-quality, security, dependency-check, docker, performance]
    if: success() # Only run if all previous jobs succeeded
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub (Optional - configure if using Docker Hub)
        # uses: docker/login-action@v3
        # with:
        #   username: ${{ secrets.DOCKER_USERNAME }}
        #   password: ${{ secrets.DOCKER_PASSWORD }}
        run: echo "Configure Docker registry login if needed"

      - name: Generate image metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: |
            todolist-backend
            # Add your registry here, e.g.:
            # gcr.io/${{ secrets.GCP_PROJECT_ID }}/todolist-backend
            # us-central1-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/todolist/backend
          tags: |
            # Branch-based tags
            type=ref,event=branch
            # PR tags  
            type=ref,event=pr,prefix=pr-
            # Semantic versioning for releases
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=semver,pattern={{major}}
            # Environment-specific tags based on branch
            type=raw,value=dev-{{date 'YYYYMMDD-HHmmss'}},enable={{is_default_branch}}
            type=raw,value=staging-{{date 'YYYYMMDD-HHmmss'}},enable=${{ github.ref == 'refs/heads/staging' }}
            type=raw,value=prod-{{date 'YYYYMMDD-HHmmss'}},enable=${{ github.ref == 'refs/heads/main' && github.event_name != 'pull_request' }}
            # Latest tag for main branch
            type=raw,value=latest,enable=${{ github.ref == 'refs/heads/main' && github.event_name != 'pull_request' }}
          labels: |
            org.opencontainers.image.title=TodoList Backend API
            org.opencontainers.image.description=AI-powered todo list backend service
            org.opencontainers.image.vendor=TodoList Team
            org.opencontainers.image.version=${{ github.sha }}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          platforms: linux/amd64,linux/arm64  # Multi-platform support
          push: false  # Set to true when registry is configured
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILDKIT_INLINE_CACHE=1

      - name: Export image for local use
        if: success()
        run: |
          # Save the image as tar for potential artifacts
          docker save todolist-backend:latest -o todolist-backend-image.tar
          echo "Image saved locally for deployment"

      - name: Generate deployment manifest
        run: |
          cat > deployment-info.json << EOF
          {
            "image_tags": "${{ steps.meta.outputs.tags }}",
            "image_digest": "${{ steps.build.outputs.digest }}",
            "commit_sha": "${{ github.sha }}",
            "branch": "${{ github.ref_name }}",
            "build_date": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "environment": "${{ github.ref == 'refs/heads/main' && 'production' || github.ref == 'refs/heads/staging' && 'staging' || 'development' }}",
            "deployment_ready": true
          }
          EOF
          echo "Deployment manifest generated"
          cat deployment-info.json

      - name: Upload image artifact (for air-gapped deployments)
        uses: actions/upload-artifact@v4
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/staging'
        with:
          name: todolist-backend-image-${{ github.ref_name }}-${{ github.run_number }}
          path: |
            todolist-backend-image.tar
            deployment-info.json
          retention-days: 30

      - name: Summary
        run: |
          echo "## 🐳 Docker Image Build Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Field | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Image Tags | ${{ steps.meta.outputs.tags }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Digest | ${{ steps.build.outputs.digest }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Commit | ${{ github.sha }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Branch | ${{ github.ref_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Environment | ${{ github.ref == 'refs/heads/main' && 'Production' || github.ref == 'refs/heads/staging' && 'Staging' || 'Development' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🚀 Next Steps for Deployment:" >> $GITHUB_STEP_SUMMARY
          echo "1. Configure container registry (GCR, GAR, or Docker Hub)" >> $GITHUB_STEP_SUMMARY
          echo "2. Set up deployment secrets (GCP_PROJECT_ID, etc.)" >> $GITHUB_STEP_SUMMARY
          echo "3. Use the generated tags for Kubernetes/GCP deployment" >> $GITHUB_STEP_SUMMARY

  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [test, code-quality, security, dependency-check, docker, performance, build-production-image]
    if: always()
    
    steps:
      - name: Check job results
        run: |
          echo "Test job: ${{ needs.test.result }}"
          echo "Code quality job: ${{ needs.code-quality.result }}"
          echo "Security job: ${{ needs.security.result }}"
          echo "Dependency check job: ${{ needs.dependency-check.result }}"
          echo "Docker job: ${{ needs.docker.result }}"
          echo "Performance job: ${{ needs.performance.result }}"
          
          if [[ "${{ needs.test.result }}" == "failure" || 
                "${{ needs.code-quality.result }}" == "failure" || 
                "${{ needs.security.result }}" == "failure" || 
                "${{ needs.docker.result }}" == "failure" || 
                "${{ needs.performance.result }}" == "failure" ]]; then
            echo "❌ CI Pipeline failed"
            exit 1
          else
            echo "✅ CI Pipeline passed"
          fi